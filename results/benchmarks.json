{
    "fastcan.FastCanBenchmark.peakmem_fit": {
        "code": "class FastCanBenchmark:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n                beam_width = 1\n            elif alg == \"eta\":\n                eta = True\n                beam_width = 1\n            else:\n                eta = False\n                beam_width = 10\n            estimator = FastCan(n_features_to_select=20, eta=eta, beam_width=beam_width)\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "fastcan.FastCanBenchmark.peakmem_fit",
        "param_names": [
            "task",
            "alg"
        ],
        "params": [
            [
                "'classif'",
                "'reg'"
            ],
            [
                "'h'",
                "'eta'",
                "'beam'"
            ]
        ],
        "setup_cache_key": "fastcan:21",
        "timeout": 500,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "fb7873a99caaa6a99dcac4db90b142f609b28eccfcb3eb9576e07d249b843050"
    },
    "fastcan.FastCanBenchmark.peakmem_transform": {
        "code": "class FastCanBenchmark:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n                beam_width = 1\n            elif alg == \"eta\":\n                eta = True\n                beam_width = 1\n            else:\n                eta = False\n                beam_width = 10\n            estimator = FastCan(n_features_to_select=20, eta=eta, beam_width=beam_width)\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "fastcan.FastCanBenchmark.peakmem_transform",
        "param_names": [
            "task",
            "alg"
        ],
        "params": [
            [
                "'classif'",
                "'reg'"
            ],
            [
                "'h'",
                "'eta'",
                "'beam'"
            ]
        ],
        "setup_cache_key": "fastcan:21",
        "timeout": 500,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "9f2913beb91eb3d038d08494b1f00d1aca36de2c06c2fcf01d970cfaa5942d35"
    },
    "fastcan.FastCanBenchmark.time_fit": {
        "code": "class FastCanBenchmark:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n                beam_width = 1\n            elif alg == \"eta\":\n                eta = True\n                beam_width = 1\n            else:\n                eta = False\n                beam_width = 10\n            estimator = FastCan(n_features_to_select=20, eta=eta, beam_width=beam_width)\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "min_run_count": 2,
        "name": "fastcan.FastCanBenchmark.time_fit",
        "number": 0,
        "param_names": [
            "task",
            "alg"
        ],
        "params": [
            [
                "'classif'",
                "'reg'"
            ],
            [
                "'h'",
                "'eta'",
                "'beam'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "fastcan:21",
        "timeout": 500,
        "type": "time",
        "unit": "seconds",
        "version": "f5d24b2951dc315a26efab4a7be4bf342d13e7399b652f44ef1ba12d0832d1b3",
        "warmup_time": -1
    },
    "fastcan.FastCanBenchmark.time_transform": {
        "code": "class FastCanBenchmark:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n                beam_width = 1\n            elif alg == \"eta\":\n                eta = True\n                beam_width = 1\n            else:\n                eta = False\n                beam_width = 10\n            estimator = FastCan(n_features_to_select=20, eta=eta, beam_width=beam_width)\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "min_run_count": 2,
        "name": "fastcan.FastCanBenchmark.time_transform",
        "number": 0,
        "param_names": [
            "task",
            "alg"
        ],
        "params": [
            [
                "'classif'",
                "'reg'"
            ],
            [
                "'h'",
                "'eta'",
                "'beam'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "fastcan:21",
        "timeout": 500,
        "type": "time",
        "unit": "seconds",
        "version": "1062e721b0492049706a9362206ef1718805514c68cc25189f79a6c6f3566f0d",
        "warmup_time": -1
    },
    "fastcan.FastCanBenchmark.track_test_score": {
        "code": "class FastCanBenchmark:\n    def track_test_score(self, *args):\n        task, _ = args\n        X_t = self.estimator.transform(self.X_val)\n        if task == \"classif\":\n            clf = LinearDiscriminantAnalysis()\n            clf.fit(X_t, self.y_val)\n            return float(clf.score(X_t, self.y_val))\n        else:\n            reg = LinearRegression()\n            reg.fit(X_t, self.y_val)\n            return float(reg.score(X_t, self.y_val))\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n                beam_width = 1\n            elif alg == \"eta\":\n                eta = True\n                beam_width = 1\n            else:\n                eta = False\n                beam_width = 10\n            estimator = FastCan(n_features_to_select=20, eta=eta, beam_width=beam_width)\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "fastcan.FastCanBenchmark.track_test_score",
        "param_names": [
            "task",
            "alg"
        ],
        "params": [
            [
                "'classif'",
                "'reg'"
            ],
            [
                "'h'",
                "'eta'",
                "'beam'"
            ]
        ],
        "setup_cache_key": "fastcan:21",
        "timeout": 500,
        "type": "track",
        "unit": "unit",
        "version": "1089d4d7729e6a7a091e12f5806930001e593e63b2d2e8af655cd55a2bc217c1"
    },
    "fastcan.FastCanBenchmark.track_train_score": {
        "code": "class FastCanBenchmark:\n    def track_train_score(self, *args):\n        task, _ = args\n        X_t = self.estimator.transform(self.X)\n        if task == \"classif\":\n            clf = LinearDiscriminantAnalysis()\n            clf.fit(X_t, self.y)\n            return float(clf.score(X_t, self.y))\n        else:\n            reg = LinearRegression()\n            reg.fit(X_t, self.y)\n            return float(reg.score(X_t, self.y))\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n                beam_width = 1\n            elif alg == \"eta\":\n                eta = True\n                beam_width = 1\n            else:\n                eta = False\n                beam_width = 10\n            estimator = FastCan(n_features_to_select=20, eta=eta, beam_width=beam_width)\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "fastcan.FastCanBenchmark.track_train_score",
        "param_names": [
            "task",
            "alg"
        ],
        "params": [
            [
                "'classif'",
                "'reg'"
            ],
            [
                "'h'",
                "'eta'",
                "'beam'"
            ]
        ],
        "setup_cache_key": "fastcan:21",
        "timeout": 500,
        "type": "track",
        "unit": "unit",
        "version": "5eaa543f882f2a3bad01f6c36a4d0d140b49cc04a365ec44567e9847070c0f5d"
    },
    "hess.HessBenchmark.peakmem_fit": {
        "code": "class HessBenchmark:\n    def peakmem_fit(self, *args):\n        solver, method = self._parse_args(*args)\n        self.estimator.fit(\n            self.X, self.y, coef_init=\"one_step_ahead\", solver=solver, method=method\n        )\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass HessBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "hess.HessBenchmark.peakmem_fit",
        "param_names": [
            "opt_alg"
        ],
        "params": [
            [
                "'lsq'",
                "'min-hess'",
                "'min-hessp'"
            ]
        ],
        "setup_cache_key": "hess:35",
        "timeout": 500,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "676560aa49582c677204b164f7654e3b2cebb812b2996edc3c73dd5bca748b16"
    },
    "hess.HessBenchmark.time_fit": {
        "code": "class HessBenchmark:\n    def time_fit(self, *args):\n        solver, method = self._parse_args(*args)\n        self.estimator.fit(\n            self.X, self.y, coef_init=\"one_step_ahead\", solver=solver, method=method\n        )\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass HessBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "min_run_count": 2,
        "name": "hess.HessBenchmark.time_fit",
        "number": 0,
        "param_names": [
            "opt_alg"
        ],
        "params": [
            [
                "'lsq'",
                "'min-hess'",
                "'min-hessp'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "hess:35",
        "timeout": 500,
        "type": "time",
        "unit": "seconds",
        "version": "e673b8188033f6075af2f9545de2225b8c0aec5a2ab7c1a82dbd9e73b4d969ce",
        "warmup_time": -1
    },
    "narx.NARXBenchmark.peakmem_fit": {
        "code": "class NARXBenchmark:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "narx.NARXBenchmark.peakmem_fit",
        "param_names": [
            "opt_alg"
        ],
        "params": [
            [
                "'osa'",
                "'msa'"
            ]
        ],
        "setup_cache_key": "narx:24",
        "timeout": 500,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "196e70bf8599ddf97952a57e076a2e6fd14fb642bef7afb8fcd32c52b76901e5"
    },
    "narx.NARXBenchmark.peakmem_predict": {
        "code": "class NARXBenchmark:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X, self.y[: self.max_delay])\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "narx.NARXBenchmark.peakmem_predict",
        "param_names": [
            "opt_alg"
        ],
        "params": [
            [
                "'osa'",
                "'msa'"
            ]
        ],
        "setup_cache_key": "narx:24",
        "timeout": 500,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "707050e4ebd1a7fea8dc3b127e937aeac112c476b3c0c98283aee9363ab16121"
    },
    "narx.NARXBenchmark.time_fit": {
        "code": "class NARXBenchmark:\n    def time_fit(self, *args):\n        (opt_alg,) = args\n        if opt_alg == \"osa\":\n            coef_init = None\n        else:\n            coef_init = [0] * (self.n_terms_to_select + 1)\n        self.estimator.fit(self.X, self.y, coef_init=coef_init)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "min_run_count": 2,
        "name": "narx.NARXBenchmark.time_fit",
        "number": 0,
        "param_names": [
            "opt_alg"
        ],
        "params": [
            [
                "'osa'",
                "'msa'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "narx:24",
        "timeout": 500,
        "type": "time",
        "unit": "seconds",
        "version": "1b206f29a096ee3ddaedc7aee7905659967932584527bf9dbe93bfcd9504937e",
        "warmup_time": -1
    },
    "narx.NARXBenchmark.time_predict": {
        "code": "class NARXBenchmark:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X, self.y[: self.max_delay])\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "min_run_count": 2,
        "name": "narx.NARXBenchmark.time_predict",
        "number": 0,
        "param_names": [
            "opt_alg"
        ],
        "params": [
            [
                "'osa'",
                "'msa'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "narx:24",
        "timeout": 500,
        "type": "time",
        "unit": "seconds",
        "version": "d4ca1c1e924260844dc01e546589313d536a80781a22a58a224ff1c726bea83c",
        "warmup_time": -1
    },
    "narx.NARXBenchmark.track_test_score": {
        "code": "class NARXBenchmark:\n    def track_test_score(self, *args):\n        y_val_pred = self.estimator.predict(\n            self.X_val,\n            self.y_val[: self.max_delay],\n        )\n        return float(r2_score(self.y_val, y_val_pred))\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "narx.NARXBenchmark.track_test_score",
        "param_names": [
            "opt_alg"
        ],
        "params": [
            [
                "'osa'",
                "'msa'"
            ]
        ],
        "setup_cache_key": "narx:24",
        "timeout": 500,
        "type": "track",
        "unit": "unit",
        "version": "29d9b2b246daebd2fd99966bd4fcefc4435fadc268d9f9447d9295f23ca794ff"
    },
    "narx.NARXBenchmark.track_train_score": {
        "code": "class NARXBenchmark:\n    def track_train_score(self, *args):\n        y_pred = self.estimator.predict(self.X, self.y[: self.max_delay])\n        return float(r2_score(self.y, y_pred))\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "narx.NARXBenchmark.track_train_score",
        "param_names": [
            "opt_alg"
        ],
        "params": [
            [
                "'osa'",
                "'msa'"
            ]
        ],
        "setup_cache_key": "narx:24",
        "timeout": 500,
        "type": "track",
        "unit": "unit",
        "version": "bd0a650ee2710599f3dd07b3bf62b0c76b621775fa5fe3ef4f89cdaf8a574398"
    },
    "version": 2
}