{"project": "fastcan", "project_url": "https://github.com/scikit-learn-contrib/fastcan", "show_commit_url": "https://github.com/scikit-learn-contrib/fastcan/commit/", "hash_length": 8, "revision_to_hash": {"3": "7d55e95299e4c95b009b5d573b8af931bea5df12", "4": "a94cf751e37d94e79300e77021179d22e7cf5c39", "5": "965c7abaad602c7f921bce7fade964d1e3dd5752", "6": "47b400aa741f752b3a8c8ca8358e149603af7600", "8": "0330a6d9c1b2da477e8164e5ed6b2ca7dc16b2ab", "9": "86456129f685e257e846f82905c285d9a8169d57", "10": "63b11f7d4a9f1ffea774d5a09666accdc9d5f3ce", "11": "b50b459469bc812479bbce53fbc0b3d18868cd05", "12": "14b8e97377a0e37950584ba039d7a66708ddf51b", "13": "a061cfb1826af31afde70130f1a1eb0eeeea5427", "14": "a53136ae81cf54611c35c391840a435a6c9db8c4", "15": "8f1242368806407dc5fb25fecccaf2c67396c117", "16": "e91259eb2de961b9c0aa312aa2fd61b2e7868a1b", "17": "52083af4ea29199be149d8d89393933c318a52eb", "18": "f636272b6ff43c2a2ca89dcddc4fc5461ff197e6", "24": "773cde74dc0fab23f9a519a817eed7f8e7dcb62f", "25": "cd78b432520751b220e9f41f446c081521a5c174", "26": "a44231054abb356d9fd94a2cbe49595ec12b098b", "27": "6714637d9b48f87251fa4a125be0ef7f584c64ac", "28": "d67306f80774413bdcdcc7d87f64819a76262b6f", "29": "74bc4cd9776a4443864fcab2728ae6d1b09fe3c1", "30": "43db3d4fbbe43040df8a461542b5664b53644963", "31": "523b38ff1e92e6119747bb97b42e526580e989bb", "37": "6082d65ebe29bea35946db1a245cfffcdb088ea1", "38": "a714c9ee6f32410b9b795aeb407debb00cbc8b6f", "39": "86923f0b926fedb57d1733cd4ba51ed3d84a2d6b", "51": "d3bc65971ecabc77e6a5280743dd3ed23f3e6499", "52": "8fbdf14477030e7e14665249b20561992dbba64a", "53": "05052aa002cf0cb14a6e781565e79c73cdf3da17", "56": "15b3df1b45064183e552f6305887c1bf72d498dc", "57": "d8c01f2d12c20b8aac6bc71d5188fc5377272e04", "58": "b42f21b43873cf76c40b84d494ce02971748a158", "60": "0e16eb1de08e19159ce2cea72073cc931e64495c", "61": "252fa20e10301f6a65b8f81ba42c44f236b7d96f", "67": "5e63efb09b2deff366771968a207606779e87b68", "72": "2475b47c1400974c7eb74b987ee4bbdaa159b438", "74": "438aa964738bec7ac3539aafb2e620ff69aba1a1", "75": "4d313e1dd99b25e942bbcb6079f9de8e81f7b9f6", "92": "07f7f66b1c43fc4ae24614bb573a19482f026537", "93": "af33941435f3d9d7e440e756948963dbdbd9d8cd", "98": "735dc0c7291b410581c566701be73007bb4a5c17", "115": "839b4e077aa1a70dbf05655003266d7a4ede71c3", "121": "aae8c9d1399c597d21c31f454aa5fef9bf06238a", "133": "6eda8c742ee2ac0ffa2d5c4b7b011ef76547cd6d", "155": "b4445d60ca330f9c822665a7eef8bcd7e62d2150", "157": "0b38856319ce003ac3a12396241caf0f9f1d9fb9", "160": "48df4914b4821f5246592082ce98b73017fd9fe8", "228": "dd18448c7c69fdc96848944b133d7122e8bf55f2", "229": "3f6e5767ea7dc8c53755332f8032f95d349e95d9", "234": "afeabc9112fbdae4a329a433041ffc93ed0f4921", "250": "8a180f6136f2cfa3e5f484658a6af1606f1e8517"}, "revision_to_date": {"3": 1719637931000, "4": 1719641346000, "5": 1719670981000, "6": 1719671884000, "8": 1719707149000, "9": 1719707469000, "10": 1719744303000, "11": 1719745511000, "12": 1719748824000, "13": 1719750831000, "14": 1719754519000, "15": 1719756722000, "16": 1719761382000, "17": 1719794106000, "18": 1719794522000, "24": 1720063751000, "25": 1720073129000, "26": 1720074147000, "27": 1720076790000, "28": 1720081996000, "29": 1720082514000, "30": 1720083931000, "31": 1720090269000, "37": 1720503216000, "38": 1720504005000, "39": 1720511155000, "51": 1721031495000, "52": 1721034133000, "53": 1721091202000, "56": 1722243699000, "57": 1722307698000, "58": 1722315729000, "60": 1722318163000, "61": 1722321232000, "67": 1722589838000, "72": 1723183722000, "74": 1723626053000, "75": 1724057592000, "92": 1726118009000, "93": 1726129069000, "98": 1726197302000, "115": 1728893672000, "121": 1729142340000, "133": 1729652625000, "155": 1736146808000, "157": 1736833353000, "160": 1739861018000, "228": 1748236931000, "229": 1748240355000, "234": 1749693062000, "250": 1755507544000}, "params": {"machine": ["macos-latest", "ubuntu-24.04-arm", "ubuntu-latest", "windows-latest"], "python": ["3.13"], "scikit-learn": [""], "pandas": [""], "branch": ["main"]}, "graph_param_list": [{"machine": "macos-latest", "python": "3.13", "scikit-learn": "", "pandas": "", "branch": "main"}, {"machine": "windows-latest", "python": "3.13", "scikit-learn": "", "pandas": "", "branch": "main"}, {"machine": "ubuntu-latest", "python": "3.13", "scikit-learn": "", "pandas": "", "branch": "main"}, {"machine": "ubuntu-24.04-arm", "python": "3.13", "scikit-learn": "", "pandas": "", "branch": "main"}], "benchmarks": {"fastcan.FastCanBenchmark.peakmem_fit": {"code": "class FastCanBenchmark:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n            else:\n                eta = True\n            estimator = FastCan(\n                n_features_to_select=20,\n                eta=eta,\n            )\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "name": "fastcan.FastCanBenchmark.peakmem_fit", "param_names": ["task", "alg"], "params": [["'classif'", "'reg'"], ["'h'", "'eta'"]], "setup_cache_key": "fastcan:21", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "2bff765ceeba8ebc662b40d48a34ddfce3f9cb16bc048bc6e29b325c0710512a"}, "fastcan.FastCanBenchmark.peakmem_transform": {"code": "class FastCanBenchmark:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n            else:\n                eta = True\n            estimator = FastCan(\n                n_features_to_select=20,\n                eta=eta,\n            )\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "name": "fastcan.FastCanBenchmark.peakmem_transform", "param_names": ["task", "alg"], "params": [["'classif'", "'reg'"], ["'h'", "'eta'"]], "setup_cache_key": "fastcan:21", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "ccc7a4f9ab9c2cfb2e82498a9466498ca9b2fb7c395e9f79c674074bb4018c00"}, "fastcan.FastCanBenchmark.time_fit": {"code": "class FastCanBenchmark:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n            else:\n                eta = True\n            estimator = FastCan(\n                n_features_to_select=20,\n                eta=eta,\n            )\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "min_run_count": 2, "name": "fastcan.FastCanBenchmark.time_fit", "number": 0, "param_names": ["task", "alg"], "params": [["'classif'", "'reg'"], ["'h'", "'eta'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "fastcan:21", "timeout": 500, "type": "time", "unit": "seconds", "version": "ae78b5ad8412ea9ee1a07ff7915c371a2bcc7c71e2a074520211654c4b317b6a", "warmup_time": -1}, "fastcan.FastCanBenchmark.time_transform": {"code": "class FastCanBenchmark:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n            else:\n                eta = True\n            estimator = FastCan(\n                n_features_to_select=20,\n                eta=eta,\n            )\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "min_run_count": 2, "name": "fastcan.FastCanBenchmark.time_transform", "number": 0, "param_names": ["task", "alg"], "params": [["'classif'", "'reg'"], ["'h'", "'eta'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "fastcan:21", "timeout": 500, "type": "time", "unit": "seconds", "version": "f567e4f5fce03709f2a8ba3b3e0989b74b5dcb32c2b83c7a3a2880f978e89f74", "warmup_time": -1}, "fastcan.FastCanBenchmark.track_test_score": {"code": "class FastCanBenchmark:\n    def track_test_score(self, *args):\n        task, _ = args\n        X_t = self.estimator.transform(self.X_val)\n        if task == \"classif\":\n            clf = LinearDiscriminantAnalysis()\n            clf.fit(X_t, self.y_val)\n            return float(clf.score(X_t, self.y_val))\n        else:\n            reg = LinearRegression()\n            reg.fit(X_t, self.y_val)\n            return float(reg.score(X_t, self.y_val))\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n            else:\n                eta = True\n            estimator = FastCan(\n                n_features_to_select=20,\n                eta=eta,\n            )\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "name": "fastcan.FastCanBenchmark.track_test_score", "param_names": ["task", "alg"], "params": [["'classif'", "'reg'"], ["'h'", "'eta'"]], "setup_cache_key": "fastcan:21", "timeout": 500, "type": "track", "unit": "unit", "version": "cb7d948ad21f20387c2971eae1703cf93c1f12021a23768380d3c5466ca156fb"}, "fastcan.FastCanBenchmark.track_train_score": {"code": "class FastCanBenchmark:\n    def track_train_score(self, *args):\n        task, _ = args\n        X_t = self.estimator.transform(self.X)\n        if task == \"classif\":\n            clf = LinearDiscriminantAnalysis()\n            clf.fit(X_t, self.y)\n            return float(clf.score(X_t, self.y))\n        else:\n            reg = LinearRegression()\n            reg.fit(X_t, self.y)\n            return float(reg.score(X_t, self.y))\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n            else:\n                eta = True\n            estimator = FastCan(\n                n_features_to_select=20,\n                eta=eta,\n            )\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "name": "fastcan.FastCanBenchmark.track_train_score", "param_names": ["task", "alg"], "params": [["'classif'", "'reg'"], ["'h'", "'eta'"]], "setup_cache_key": "fastcan:21", "timeout": 500, "type": "track", "unit": "unit", "version": "fd8a3aceddb21b108152ae90e36f9021df59130b996bf33156f1b75479f1d12e"}, "narx.NARXBenchmark.peakmem_fit": {"code": "class NARXBenchmark:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "name": "narx.NARXBenchmark.peakmem_fit", "param_names": ["opt_alg"], "params": [["'osa'", "'msa'"]], "setup_cache_key": "narx:24", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "196e70bf8599ddf97952a57e076a2e6fd14fb642bef7afb8fcd32c52b76901e5"}, "narx.NARXBenchmark.peakmem_predict": {"code": "class NARXBenchmark:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X, self.y[: self.max_delay])\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "name": "narx.NARXBenchmark.peakmem_predict", "param_names": ["opt_alg"], "params": [["'osa'", "'msa'"]], "setup_cache_key": "narx:24", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "707050e4ebd1a7fea8dc3b127e937aeac112c476b3c0c98283aee9363ab16121"}, "narx.NARXBenchmark.time_fit": {"code": "class NARXBenchmark:\n    def time_fit(self, *args):\n        (opt_alg,) = args\n        if opt_alg == \"osa\":\n            coef_init = None\n        else:\n            coef_init = [0] * (self.n_terms_to_select + 1)\n        self.estimator.fit(self.X, self.y, coef_init=coef_init)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "min_run_count": 2, "name": "narx.NARXBenchmark.time_fit", "number": 0, "param_names": ["opt_alg"], "params": [["'osa'", "'msa'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "narx:24", "timeout": 500, "type": "time", "unit": "seconds", "version": "1b206f29a096ee3ddaedc7aee7905659967932584527bf9dbe93bfcd9504937e", "warmup_time": -1}, "narx.NARXBenchmark.time_predict": {"code": "class NARXBenchmark:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X, self.y[: self.max_delay])\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "min_run_count": 2, "name": "narx.NARXBenchmark.time_predict", "number": 0, "param_names": ["opt_alg"], "params": [["'osa'", "'msa'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "narx:24", "timeout": 500, "type": "time", "unit": "seconds", "version": "d4ca1c1e924260844dc01e546589313d536a80781a22a58a224ff1c726bea83c", "warmup_time": -1}, "narx.NARXBenchmark.track_test_score": {"code": "class NARXBenchmark:\n    def track_test_score(self, *args):\n        y_val_pred = self.estimator.predict(\n            self.X_val,\n            self.y_val[: self.max_delay],\n        )\n        return float(r2_score(self.y_val, y_val_pred))\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "name": "narx.NARXBenchmark.track_test_score", "param_names": ["opt_alg"], "params": [["'osa'", "'msa'"]], "setup_cache_key": "narx:24", "timeout": 500, "type": "track", "unit": "unit", "version": "29d9b2b246daebd2fd99966bd4fcefc4435fadc268d9f9447d9295f23ca794ff"}, "narx.NARXBenchmark.track_train_score": {"code": "class NARXBenchmark:\n    def track_train_score(self, *args):\n        y_pred = self.estimator.predict(self.X, self.y[: self.max_delay])\n        return float(r2_score(self.y, y_pred))\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "name": "narx.NARXBenchmark.track_train_score", "param_names": ["opt_alg"], "params": [["'osa'", "'msa'"]], "setup_cache_key": "narx:24", "timeout": 500, "type": "track", "unit": "unit", "version": "bd0a650ee2710599f3dd07b3bf62b0c76b621775fa5fe3ef4f89cdaf8a574398"}}, "machines": {"macos-latest": {"machine": "macos-latest", "version": 1}, "windows-latest": {"machine": "windows-latest", "version": 1}, "ubuntu-latest": {"machine": "ubuntu-latest", "version": 1}, "ubuntu-24.04-arm": {"machine": "ubuntu-24.04-arm", "version": 1}}, "tags": {"v0.1.0": 3, "v0.1.1": 4, "v0.1.10": 14, "v0.1.11": 15, "v0.1.12": 16, "v0.1.13": 17, "v0.1.14": 18, "v0.1.15": 24, "v0.1.16": 25, "v0.1.17": 26, "v0.1.18": 27, "v0.1.19": 28, "v0.1.2": 5, "v0.1.20": 29, "v0.1.21": 30, "v0.1.22": 31, "v0.1.23": 37, "v0.1.24": 38, "v0.1.25": 39, "v0.1.26": 51, "v0.1.27": 52, "v0.1.28": 53, "v0.1.29": 56, "v0.1.3": 6, "v0.1.30": 56, "v0.1.31": 57, "v0.1.32": 58, "v0.1.33": 60, "v0.1.34": 61, "v0.1.35": 67, "v0.1.37": 72, "v0.1.4": 8, "v0.1.5": 9, "v0.1.6": 10, "v0.1.7": 11, "v0.1.8": 12, "v0.1.9": 13, "v0.2.0": 74, "v0.2.1": 75, "v0.2.2": 92, "v0.2.3": 93, "v0.2.4": 98, "v0.2.5": 115, "v0.2.6": 121, "v0.2.7": 133, "v0.3.0": 155, "v0.3.1": 157, "v0.3.2": 160, "v0.4.0": 234, "v0.4.0-pre": 228, "v0.4.0-pre.1": 229}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}