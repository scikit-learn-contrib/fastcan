{"project": "fastcan", "project_url": "https://github.com/scikit-learn-contrib/fastcan", "show_commit_url": "https://github.com/scikit-learn-contrib/fastcan/commit/", "hash_length": 8, "revision_to_hash": {"3": "7d55e95299e4c95b009b5d573b8af931bea5df12", "4": "a94cf751e37d94e79300e77021179d22e7cf5c39", "5": "965c7abaad602c7f921bce7fade964d1e3dd5752", "6": "47b400aa741f752b3a8c8ca8358e149603af7600", "8": "0330a6d9c1b2da477e8164e5ed6b2ca7dc16b2ab", "9": "86456129f685e257e846f82905c285d9a8169d57", "10": "63b11f7d4a9f1ffea774d5a09666accdc9d5f3ce", "11": "b50b459469bc812479bbce53fbc0b3d18868cd05", "12": "14b8e97377a0e37950584ba039d7a66708ddf51b", "13": "a061cfb1826af31afde70130f1a1eb0eeeea5427", "14": "a53136ae81cf54611c35c391840a435a6c9db8c4", "15": "8f1242368806407dc5fb25fecccaf2c67396c117", "16": "e91259eb2de961b9c0aa312aa2fd61b2e7868a1b", "17": "52083af4ea29199be149d8d89393933c318a52eb", "18": "f636272b6ff43c2a2ca89dcddc4fc5461ff197e6", "24": "773cde74dc0fab23f9a519a817eed7f8e7dcb62f", "25": "cd78b432520751b220e9f41f446c081521a5c174", "26": "a44231054abb356d9fd94a2cbe49595ec12b098b", "27": "6714637d9b48f87251fa4a125be0ef7f584c64ac", "28": "d67306f80774413bdcdcc7d87f64819a76262b6f", "29": "74bc4cd9776a4443864fcab2728ae6d1b09fe3c1", "30": "43db3d4fbbe43040df8a461542b5664b53644963", "31": "523b38ff1e92e6119747bb97b42e526580e989bb", "37": "6082d65ebe29bea35946db1a245cfffcdb088ea1", "38": "a714c9ee6f32410b9b795aeb407debb00cbc8b6f", "39": "86923f0b926fedb57d1733cd4ba51ed3d84a2d6b", "51": "d3bc65971ecabc77e6a5280743dd3ed23f3e6499", "52": "8fbdf14477030e7e14665249b20561992dbba64a", "53": "05052aa002cf0cb14a6e781565e79c73cdf3da17", "56": "15b3df1b45064183e552f6305887c1bf72d498dc", "57": "d8c01f2d12c20b8aac6bc71d5188fc5377272e04", "58": "b42f21b43873cf76c40b84d494ce02971748a158", "60": "0e16eb1de08e19159ce2cea72073cc931e64495c", "61": "252fa20e10301f6a65b8f81ba42c44f236b7d96f", "67": "5e63efb09b2deff366771968a207606779e87b68", "72": "2475b47c1400974c7eb74b987ee4bbdaa159b438", "74": "438aa964738bec7ac3539aafb2e620ff69aba1a1", "75": "4d313e1dd99b25e942bbcb6079f9de8e81f7b9f6", "92": "07f7f66b1c43fc4ae24614bb573a19482f026537", "93": "af33941435f3d9d7e440e756948963dbdbd9d8cd", "98": "735dc0c7291b410581c566701be73007bb4a5c17", "115": "839b4e077aa1a70dbf05655003266d7a4ede71c3", "121": "aae8c9d1399c597d21c31f454aa5fef9bf06238a", "133": "6eda8c742ee2ac0ffa2d5c4b7b011ef76547cd6d", "155": "b4445d60ca330f9c822665a7eef8bcd7e62d2150", "157": "0b38856319ce003ac3a12396241caf0f9f1d9fb9", "160": "48df4914b4821f5246592082ce98b73017fd9fe8", "228": "dd18448c7c69fdc96848944b133d7122e8bf55f2", "229": "3f6e5767ea7dc8c53755332f8032f95d349e95d9", "234": "afeabc9112fbdae4a329a433041ffc93ed0f4921", "250": "8a180f6136f2cfa3e5f484658a6af1606f1e8517", "252": "69ee1cdbd0744dc180af3875e8f2230bee16bfdc", "254": "f78f9042d59b317908497b9ff2d0234f675d33af", "256": "90a5c54367d4b327b58a4c3706390fb7961d6d84", "258": "8b6a1b21eb5d2d2477a66c41be2a036b15afbf3f", "260": "4f801f4f931396f838b5ff2df3dcf445f9683660", "262": "55d9e067316bb03ae45960733a06b26b462d3d8d", "264": "48cc6504f6a04774fe68ab16855403485ed111ea", "266": "9fbfb90f0def396f74d0c093fd14f28cedc1e846", "268": "cb6a3b1e7175435d9abef57f000eb063e24eae7d", "270": "30e3a17be5ef4428d4dab6a0903221c389d62706", "272": "2e9735b9664335e07817560b48b603fbdd87652f", "274": "9e9bd2ebb3a09481d2e0c7c228c6dd1e03fa4ec3", "276": "e5cbafaf78551e8a90abe201dd1cb7def236378c", "279": "05533fd6abee65459a2965e1ba420085b2c9f0e0", "281": "b621f9ccbc9c058e5a0961f68a8b86f63678ac23", "283": "286a7ee1a9b21f12d02eb8a124712d946f6c81cd", "285": "8bf95b437fdc2a3a1845663d1e34040083eb77af", "287": "c2a8ca56f661620d7a4f058da8e7d383b3a295c3", "289": "c1a4e438c6068097499e34ea60323a1c9df90ec8", "291": "e47b6fab6a9374f36d46ee94804a154f1526da81", "293": "085a225f9081972ae96d966fe060ab2195b8fe52", "295": "2baa25ecf9af98e165a44e3246a03499b3ec3a0b", "297": "fac6872d59e410c788bc18c90d758eb618a208d4", "299": "509ee9ce7c022dc75043990b80922ed83c3ae316", "301": "5c2dbe34704365be0b510e425aa9a623dfb3549e", "303": "b9c9d8a0f8a9a4fbfa5010e390aa62b1b9cbfcd9", "305": "0ad587585a07f56c9665b1aef4c8d27d25003a37", "307": "30889b7fe323e38d3e4fc3e2139243ccfa6fbbf7", "309": "122d00f3ae1bdff664901e0bd7a48e84d6cd0617", "311": "2b6272d41ee36c3950e21fb0876e8c814239fcde", "313": "ac90c154e0532a05a2c7fbbd575233193b7c0a90", "315": "66787caebd1e5da578634e2d8d823f76dfab8ac6"}, "revision_to_date": {"3": 1719637931000, "4": 1719641346000, "5": 1719670981000, "6": 1719671884000, "8": 1719707149000, "9": 1719707469000, "10": 1719744303000, "11": 1719745511000, "12": 1719748824000, "13": 1719750831000, "14": 1719754519000, "15": 1719756722000, "16": 1719761382000, "17": 1719794106000, "18": 1719794522000, "24": 1720063751000, "25": 1720073129000, "26": 1720074147000, "27": 1720076790000, "28": 1720081996000, "29": 1720082514000, "30": 1720083931000, "31": 1720090269000, "37": 1720503216000, "38": 1720504005000, "39": 1720511155000, "51": 1721031495000, "52": 1721034133000, "53": 1721091202000, "56": 1722243699000, "57": 1722307698000, "58": 1722315729000, "60": 1722318163000, "61": 1722321232000, "67": 1722589838000, "72": 1723183722000, "74": 1723626053000, "75": 1724057592000, "92": 1726118009000, "93": 1726129069000, "98": 1726197302000, "115": 1728893672000, "121": 1729142340000, "133": 1729652625000, "155": 1736146808000, "157": 1736833353000, "160": 1739861018000, "228": 1748236931000, "229": 1748240355000, "234": 1749693062000, "250": 1755507544000, "252": 1755572991000, "254": 1755580718000, "256": 1755681235000, "258": 1755682947000, "260": 1755695467000, "262": 1756276868000, "264": 1756798152000, "266": 1756801285000, "268": 1756973829000, "270": 1757490151000, "272": 1757493760000, "274": 1757498494000, "276": 1757581925000, "279": 1758625553000, "281": 1759377040000, "283": 1759492933000, "285": 1759575190000, "287": 1760428003000, "289": 1760583968000, "291": 1761029782000, "293": 1761397667000, "295": 1761657721000, "297": 1762225957000, "299": 1762425549000, "301": 1762605010000, "303": 1762930228000, "305": 1763181398000, "307": 1763454393000, "309": 1763523351000, "311": 1764313344000, "313": 1765507420000, "315": 1765763674000}, "params": {"machine": ["macos-latest", "ubuntu-24.04-arm", "ubuntu-latest", "windows-latest"], "python": ["3.13"], "scikit-learn": [""], "pandas": [""], "branch": ["main"]}, "graph_param_list": [{"machine": "windows-latest", "python": "3.13", "scikit-learn": "", "pandas": "", "branch": "main"}, {"machine": "ubuntu-24.04-arm", "python": "3.13", "scikit-learn": "", "pandas": "", "branch": "main"}, {"machine": "macos-latest", "python": "3.13", "scikit-learn": "", "pandas": "", "branch": "main"}, {"machine": "ubuntu-latest", "python": "3.13", "scikit-learn": "", "pandas": "", "branch": "main"}], "benchmarks": {"fastcan.FastCanBenchmark.peakmem_fit": {"code": "class FastCanBenchmark:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n                beam_width = 1\n            elif alg == \"eta\":\n                eta = True\n                beam_width = 1\n            else:\n                eta = False\n                beam_width = 10\n            estimator = FastCan(n_features_to_select=20, eta=eta, beam_width=beam_width)\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "name": "fastcan.FastCanBenchmark.peakmem_fit", "param_names": ["task", "alg"], "params": [["'classif'", "'reg'"], ["'h'", "'eta'", "'beam'"]], "setup_cache_key": "fastcan:21", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "fb7873a99caaa6a99dcac4db90b142f609b28eccfcb3eb9576e07d249b843050"}, "fastcan.FastCanBenchmark.peakmem_transform": {"code": "class FastCanBenchmark:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n                beam_width = 1\n            elif alg == \"eta\":\n                eta = True\n                beam_width = 1\n            else:\n                eta = False\n                beam_width = 10\n            estimator = FastCan(n_features_to_select=20, eta=eta, beam_width=beam_width)\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "name": "fastcan.FastCanBenchmark.peakmem_transform", "param_names": ["task", "alg"], "params": [["'classif'", "'reg'"], ["'h'", "'eta'", "'beam'"]], "setup_cache_key": "fastcan:21", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "9f2913beb91eb3d038d08494b1f00d1aca36de2c06c2fcf01d970cfaa5942d35"}, "fastcan.FastCanBenchmark.time_fit": {"code": "class FastCanBenchmark:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n                beam_width = 1\n            elif alg == \"eta\":\n                eta = True\n                beam_width = 1\n            else:\n                eta = False\n                beam_width = 10\n            estimator = FastCan(n_features_to_select=20, eta=eta, beam_width=beam_width)\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "min_run_count": 2, "name": "fastcan.FastCanBenchmark.time_fit", "number": 0, "param_names": ["task", "alg"], "params": [["'classif'", "'reg'"], ["'h'", "'eta'", "'beam'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "fastcan:21", "timeout": 500, "type": "time", "unit": "seconds", "version": "f5d24b2951dc315a26efab4a7be4bf342d13e7399b652f44ef1ba12d0832d1b3", "warmup_time": -1}, "fastcan.FastCanBenchmark.time_transform": {"code": "class FastCanBenchmark:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n                beam_width = 1\n            elif alg == \"eta\":\n                eta = True\n                beam_width = 1\n            else:\n                eta = False\n                beam_width = 10\n            estimator = FastCan(n_features_to_select=20, eta=eta, beam_width=beam_width)\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "min_run_count": 2, "name": "fastcan.FastCanBenchmark.time_transform", "number": 0, "param_names": ["task", "alg"], "params": [["'classif'", "'reg'"], ["'h'", "'eta'", "'beam'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "fastcan:21", "timeout": 500, "type": "time", "unit": "seconds", "version": "1062e721b0492049706a9362206ef1718805514c68cc25189f79a6c6f3566f0d", "warmup_time": -1}, "fastcan.FastCanBenchmark.track_test_score": {"code": "class FastCanBenchmark:\n    def track_test_score(self, *args):\n        task, _ = args\n        X_t = self.estimator.transform(self.X_val)\n        if task == \"classif\":\n            clf = LinearDiscriminantAnalysis()\n            clf.fit(X_t, self.y_val)\n            return float(clf.score(X_t, self.y_val))\n        else:\n            reg = LinearRegression()\n            reg.fit(X_t, self.y_val)\n            return float(reg.score(X_t, self.y_val))\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n                beam_width = 1\n            elif alg == \"eta\":\n                eta = True\n                beam_width = 1\n            else:\n                eta = False\n                beam_width = 10\n            estimator = FastCan(n_features_to_select=20, eta=eta, beam_width=beam_width)\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "name": "fastcan.FastCanBenchmark.track_test_score", "param_names": ["task", "alg"], "params": [["'classif'", "'reg'"], ["'h'", "'eta'", "'beam'"]], "setup_cache_key": "fastcan:21", "timeout": 500, "type": "track", "unit": "unit", "version": "1089d4d7729e6a7a091e12f5806930001e593e63b2d2e8af655cd55a2bc217c1"}, "fastcan.FastCanBenchmark.track_train_score": {"code": "class FastCanBenchmark:\n    def track_train_score(self, *args):\n        task, _ = args\n        X_t = self.estimator.transform(self.X)\n        if task == \"classif\":\n            clf = LinearDiscriminantAnalysis()\n            clf.fit(X_t, self.y)\n            return float(clf.score(X_t, self.y))\n        else:\n            reg = LinearRegression()\n            reg.fit(X_t, self.y)\n            return float(reg.score(X_t, self.y))\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n                beam_width = 1\n            elif alg == \"eta\":\n                eta = True\n                beam_width = 1\n            else:\n                eta = False\n                beam_width = 10\n            estimator = FastCan(n_features_to_select=20, eta=eta, beam_width=beam_width)\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "name": "fastcan.FastCanBenchmark.track_train_score", "param_names": ["task", "alg"], "params": [["'classif'", "'reg'"], ["'h'", "'eta'", "'beam'"]], "setup_cache_key": "fastcan:21", "timeout": 500, "type": "track", "unit": "unit", "version": "5eaa543f882f2a3bad01f6c36a4d0d140b49cc04a365ec44567e9847070c0f5d"}, "narx.NARXBenchmark.peakmem_fit": {"code": "class NARXBenchmark:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "name": "narx.NARXBenchmark.peakmem_fit", "param_names": ["opt_alg"], "params": [["'osa'", "'msa'"]], "setup_cache_key": "narx:24", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "196e70bf8599ddf97952a57e076a2e6fd14fb642bef7afb8fcd32c52b76901e5"}, "narx.NARXBenchmark.peakmem_predict": {"code": "class NARXBenchmark:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X, self.y[: self.max_delay])\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "name": "narx.NARXBenchmark.peakmem_predict", "param_names": ["opt_alg"], "params": [["'osa'", "'msa'"]], "setup_cache_key": "narx:24", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "707050e4ebd1a7fea8dc3b127e937aeac112c476b3c0c98283aee9363ab16121"}, "narx.NARXBenchmark.time_fit": {"code": "class NARXBenchmark:\n    def time_fit(self, *args):\n        (opt_alg,) = args\n        if opt_alg == \"osa\":\n            coef_init = None\n        else:\n            coef_init = [0] * (self.n_terms_to_select + 1)\n        self.estimator.fit(self.X, self.y, coef_init=coef_init)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "min_run_count": 2, "name": "narx.NARXBenchmark.time_fit", "number": 0, "param_names": ["opt_alg"], "params": [["'osa'", "'msa'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "narx:24", "timeout": 500, "type": "time", "unit": "seconds", "version": "1b206f29a096ee3ddaedc7aee7905659967932584527bf9dbe93bfcd9504937e", "warmup_time": -1}, "narx.NARXBenchmark.time_predict": {"code": "class NARXBenchmark:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X, self.y[: self.max_delay])\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "min_run_count": 2, "name": "narx.NARXBenchmark.time_predict", "number": 0, "param_names": ["opt_alg"], "params": [["'osa'", "'msa'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "setup_cache_key": "narx:24", "timeout": 500, "type": "time", "unit": "seconds", "version": "d4ca1c1e924260844dc01e546589313d536a80781a22a58a224ff1c726bea83c", "warmup_time": -1}, "narx.NARXBenchmark.track_test_score": {"code": "class NARXBenchmark:\n    def track_test_score(self, *args):\n        y_val_pred = self.estimator.predict(\n            self.X_val,\n            self.y_val[: self.max_delay],\n        )\n        return float(r2_score(self.y_val, y_val_pred))\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "name": "narx.NARXBenchmark.track_test_score", "param_names": ["opt_alg"], "params": [["'osa'", "'msa'"]], "setup_cache_key": "narx:24", "timeout": 500, "type": "track", "unit": "unit", "version": "29d9b2b246daebd2fd99966bd4fcefc4435fadc268d9f9447d9295f23ca794ff"}, "narx.NARXBenchmark.track_train_score": {"code": "class NARXBenchmark:\n    def track_train_score(self, *args):\n        y_pred = self.estimator.predict(self.X, self.y[: self.max_delay])\n        return float(r2_score(self.y, y_pred))\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)", "name": "narx.NARXBenchmark.track_train_score", "param_names": ["opt_alg"], "params": [["'osa'", "'msa'"]], "setup_cache_key": "narx:24", "timeout": 500, "type": "track", "unit": "unit", "version": "bd0a650ee2710599f3dd07b3bf62b0c76b621775fa5fe3ef4f89cdaf8a574398"}}, "machines": {"windows-latest": {"machine": "windows-latest", "version": 1}, "ubuntu-24.04-arm": {"machine": "ubuntu-24.04-arm", "version": 1}, "macos-latest": {"machine": "macos-latest", "version": 1}, "ubuntu-latest": {"machine": "ubuntu-latest", "version": 1}}, "tags": {"v0.1.0": 3, "v0.1.1": 4, "v0.1.10": 14, "v0.1.11": 15, "v0.1.12": 16, "v0.1.13": 17, "v0.1.14": 18, "v0.1.15": 24, "v0.1.16": 25, "v0.1.17": 26, "v0.1.18": 27, "v0.1.19": 28, "v0.1.2": 5, "v0.1.20": 29, "v0.1.21": 30, "v0.1.22": 31, "v0.1.23": 37, "v0.1.24": 38, "v0.1.25": 39, "v0.1.26": 51, "v0.1.27": 52, "v0.1.28": 53, "v0.1.29": 56, "v0.1.3": 6, "v0.1.30": 56, "v0.1.31": 57, "v0.1.32": 58, "v0.1.33": 60, "v0.1.34": 61, "v0.1.35": 67, "v0.1.37": 72, "v0.1.4": 8, "v0.1.5": 9, "v0.1.6": 10, "v0.1.7": 11, "v0.1.8": 12, "v0.1.9": 13, "v0.2.0": 74, "v0.2.1": 75, "v0.2.2": 92, "v0.2.3": 93, "v0.2.4": 98, "v0.2.5": 115, "v0.2.6": 121, "v0.2.7": 133, "v0.3.0": 155, "v0.3.1": 157, "v0.3.2": 160, "v0.4.0": 234, "v0.4.0-pre": 228, "v0.4.0-pre.1": 229, "v0.4.1": 274, "v0.4.1-alpha": 270, "v0.4.1-alpha.2": 272, "v0.4.1-alpha.3": 274}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}